{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SNIP_reimplementation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prokorpio/everything_190/blob/master/SNIP_reimplementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0kkUsgZ25Ig",
        "colab_type": "text"
      },
      "source": [
        "# SNIP Reimplementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndqT7oLK21yS",
        "colab_type": "text"
      },
      "source": [
        "## 1. Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYdYODVYjxqG",
        "colab_type": "code",
        "outputId": "25b5cb3a-b65a-4815-a929-26b2d139b88f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print('Tensorflow v', tf.__version__, sep='')\n",
        "from platform import python_version\n",
        "print('python v',python_version(), sep='')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D\n",
        "from tensorflow.keras.initializers import VarianceScaling\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "import keras.backend as K\n",
        "import keras\n",
        "print('Keras v',keras.__version__,sep='')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow v1.15.0-rc3\n",
            "python v3.6.8\n",
            "Keras v2.2.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lixkD3g43Cr-",
        "colab_type": "text"
      },
      "source": [
        "## 2. Setup Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7nbgBIVlikd",
        "colab_type": "code",
        "outputId": "b735c397-bdc0-4c7c-b895-16855f14451d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# load mnist\n",
        "(x, y), (x_test, y_test) = mnist.load_data()\n",
        "img_size = x.shape[1:] # shape = [m, h, w]\n",
        "\n",
        "# normalize\n",
        "x = x.astype('float32')/255\n",
        "x_test = x_test.astype('float32')/255\n",
        "\n",
        "# split train:validation as 90%:10%\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.1, shuffle=False)\n",
        "\n",
        "# convert y labels to one-hot vectors\n",
        "num_classes = len(np.unique(y_test))\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_valid = to_categorical(y_valid, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "# view sample shape\n",
        "print('x_train shape:',x_train.shape)\n",
        "print('x_valid shape:',x_valid.shape)\n",
        "print('y_valid shape:',y_valid.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (54000, 28, 28)\n",
            "x_valid shape: (6000, 28, 28)\n",
            "y_valid shape: (6000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1IZjHhHCGJu",
        "colab_type": "text"
      },
      "source": [
        "## 3. Create Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO5jUk28XRpJ",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Define Custom Layers "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYQpEqbpXRHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# source: https://stackoverflow.com/questions/50290769/specify-connections-in-nn-in-keras\n",
        "\n",
        "class PrunableDense(Dense):\n",
        "\n",
        "    def __init__(self,units,mask,**kwargs):\n",
        "          \n",
        "        self.mask = mask         \n",
        "\n",
        "        #initalize the original Dense with all the usual arguments   \n",
        "        super(PrunableDense,self).__init__(units,**kwargs)  \n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = K.dot(inputs, self.kernel * self.mask)\n",
        "        if self.use_bias:\n",
        "            output = K.bias_add(output, self.bias)\n",
        "        if self.activation is not None:\n",
        "            output = self.activation(output)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fM7_9NIsFg2",
        "colab_type": "code",
        "outputId": "88b54149-673f-4f6b-8207-ebf1625f0b95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "# define simple network\n",
        "X_input = Input(shape = 4) \n",
        "X = PrunableDense(3,\n",
        "                  mask=tf.Variable([[0,0,0],[1,1,1],[1,1,1],[1,1,1]],\n",
        "                                   dtype = 'float32',\n",
        "                                   trainable=False),\n",
        "                  kernel_initializer = tf.keras.initializers.Constant(value=2),\n",
        "                  use_bias=0)(X_input)\n",
        "X = PrunableDense(2,\n",
        "                  mask= np.array([[1,1],[1,1],[1,1]]),\n",
        "                  kernel_initializer = tf.keras.initializers.Constant(value=2),\n",
        "                  use_bias=0)(X)\n",
        "X = Dense(1,\n",
        "          kernel_initializer = tf.keras.initializers.Constant(value=1),\n",
        "          use_bias = 0)(X)\n",
        "\n",
        "model = Model(inputs=X_input, outputs=X)\n",
        "\n",
        "model.summary()\n",
        "for layer in model.trainable_weights:\n",
        "    print(layer.shape)\n",
        "    #print(layer.get_weights()[1].shape)\n",
        "    "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
            "\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 4)]               0         \n",
            "_________________________________________________________________\n",
            "prunable_dense (PrunableDens (None, 3)                 24        \n",
            "_________________________________________________________________\n",
            "prunable_dense_1 (PrunableDe (None, 2)                 6         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 32\n",
            "Trainable params: 20\n",
            "Non-trainable params: 12\n",
            "_________________________________________________________________\n",
            "(4, 3)\n",
            "(3, 2)\n",
            "(2, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0uZIO05vnog",
        "colab_type": "code",
        "outputId": "187b87f6-b24a-4e5b-e295-2c409c50ee59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "inputa = np.ones(shape=(2,4)) #2 samples, 4 features\n",
        "print(inputa)\n",
        "model.predict(inputa)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[72.],\n",
              "       [72.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQS8V1fc1E2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "grad = K.gradients(model.outputs,model.trainable_weights)\n",
        "\n",
        "trainingExample = np.ones(shape=(2,4))\n",
        "#tf.InteractiveSession().close()\n",
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "evaluated_gradients = sess.run(grad,feed_dict={model.input:trainingExample})\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_wbwBuz2kuL",
        "colab_type": "code",
        "outputId": "bb07d81b-1c01-4b0d-eede-1b3b6fe25e54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(evaluated_gradients)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[0., 0., 0.],\n",
            "       [8., 8., 8.],\n",
            "       [8., 8., 8.],\n",
            "       [8., 8., 8.]], dtype=float32), array([[12., 12.],\n",
            "       [12., 12.],\n",
            "       [12., 12.]], dtype=float32), array([[72.],\n",
            "       [72.]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpJ5LfSXzHjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "i = 0\n",
        "grads = {0:0,1:0}\n",
        "for layer in model.layers[1:]:\n",
        "    grads[i] = K.gradients(model.outputs,model.trainable_weights)\n",
        "    i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHNcXFBvXZ49",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Construct Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Emqg7qU34dNs",
        "colab_type": "code",
        "outputId": "1256cc8a-97e4-44d3-c107-8319395114ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "def LeNet_300_100(input_shape, num_classes,mask=[1,1,1]):\n",
        "    \"\"\" \n",
        "    LeNet 3-Layer FC implementation\n",
        "    \"\"\"\n",
        "    \n",
        "    vs = VarianceScaling()\n",
        "    \n",
        "    X_input = Input(shape = input_shape)\n",
        "    X = Flatten()(X_input) # 28 * 28 = 784\n",
        "    X = PrunableDense(300, \n",
        "                      mask = mask[0],\n",
        "                      use_bias = False,\n",
        "                      kernel_initializer = vs,\n",
        "                      activation='relu')(X) \n",
        "    X = PrunableDense(100,\n",
        "                      mask = mask[1],\n",
        "                      use_bias = False,\n",
        "                      kernel_initializer = vs,\n",
        "                      activation='relu')(X)\n",
        "    X = PrunableDense(num_classes, \n",
        "                      mask = mask[2],\n",
        "                      use_bias = False,\n",
        "                      kernel_initializer = vs,\n",
        "                      activation='softmax')(X)\n",
        "    \n",
        "    return Model(inputs=X_input, outputs=X)\n",
        "\n",
        "LeNet = LeNet_300_100(img_size, num_classes)\n",
        "LeNet.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
            "\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "prunable_dense (PrunableDens (None, 300)               235200    \n",
            "_________________________________________________________________\n",
            "prunable_dense_1 (PrunableDe (None, 100)               30000     \n",
            "_________________________________________________________________\n",
            "prunable_dense_2 (PrunableDe (None, 10)                1000      \n",
            "=================================================================\n",
            "Total params: 266,200\n",
            "Trainable params: 266,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl2UYsf7Q5s9",
        "colab_type": "text"
      },
      "source": [
        "## 4. Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEtX3BNt4haS",
        "colab_type": "code",
        "outputId": "3d0e0825-a831-4d60-ca20-35055fcafb30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "# setup Hyperparams\n",
        "SGDdizer = SGD(lr=0.1,\n",
        "               momentum = 0.9,\n",
        "               decay = 0.0005)\n",
        "LeNet.compile(optimizer=SGDdizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "batch_size = 100\n",
        "epochs = 10\n",
        "    \n",
        "# fit model\n",
        "trainings = []\n",
        "\n",
        "start_time = time.time()\n",
        "trainings.append(LeNet.fit(\n",
        "                  x_train, y_train,\n",
        "                  batch_size = batch_size,\n",
        "                  epochs = epochs,\n",
        "                  validation_data = (x_valid, y_valid)))\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "time.strftime(\"Total training time  = %H:%M:%S\", time.gmtime(elapsed_time))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/10\n",
            "54000/54000 [==============================] - 3s 53us/sample - loss: 0.2667 - acc: 0.9184 - val_loss: 0.1118 - val_acc: 0.9668\n",
            "Epoch 2/10\n",
            "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0928 - acc: 0.9713 - val_loss: 0.0852 - val_acc: 0.9737\n",
            "Epoch 3/10\n",
            "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0575 - acc: 0.9821 - val_loss: 0.0793 - val_acc: 0.9767\n",
            "Epoch 4/10\n",
            "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0372 - acc: 0.9887 - val_loss: 0.0711 - val_acc: 0.9793\n",
            "Epoch 5/10\n",
            "54000/54000 [==============================] - 2s 36us/sample - loss: 0.0235 - acc: 0.9929 - val_loss: 0.0725 - val_acc: 0.9797\n",
            "Epoch 6/10\n",
            "54000/54000 [==============================] - 2s 36us/sample - loss: 0.0147 - acc: 0.9958 - val_loss: 0.0663 - val_acc: 0.9830\n",
            "Epoch 7/10\n",
            "54000/54000 [==============================] - 2s 36us/sample - loss: 0.0092 - acc: 0.9977 - val_loss: 0.0664 - val_acc: 0.9833\n",
            "Epoch 8/10\n",
            "54000/54000 [==============================] - 2s 36us/sample - loss: 0.0063 - acc: 0.9986 - val_loss: 0.0693 - val_acc: 0.9830\n",
            "Epoch 9/10\n",
            "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0044 - acc: 0.9994 - val_loss: 0.0686 - val_acc: 0.9832\n",
            "Epoch 10/10\n",
            "54000/54000 [==============================] - 2s 36us/sample - loss: 0.0029 - acc: 0.9998 - val_loss: 0.0710 - val_acc: 0.9832\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Total training time  = 00:00:25'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhKpN-0tTxcv",
        "colab_type": "text"
      },
      "source": [
        "## 5. Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLPkeYsbM74j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_trainings(trainings):\n",
        "    plt.clf()\n",
        "    acc = []\n",
        "    val_acc = []\n",
        "    loss = []\n",
        "    val_loss = []\n",
        "\n",
        "    # concatenate all data points for all trainings\n",
        "    for train in trainings:\n",
        "        for point in train.history['acc']:\n",
        "            acc.append(point)\n",
        "        for point in train.history['val_acc']:\n",
        "            val_acc.append(point)\n",
        "        for point in train.history['loss']:\n",
        "            loss.append(point)\n",
        "        for point in train.history['val_loss']:\n",
        "            val_loss.append(point)\n",
        "    #epochs = range(1, len(mae) + 1)\n",
        "\n",
        "    # Plot training history for accuracy\n",
        "    plt.plot(acc)\n",
        "    plt.plot(val_acc)\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp6JQMvxUg1g",
        "colab_type": "code",
        "outputId": "f2f33287-c1d3-47c3-c6a5-b9bdd9f63a82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "preds = LeNet.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "plot_trainings(trainings)\n",
        "print(\"\\nTest Error: {:.2%}\\n\".format(1-preds[1])) # should get 1.65ish error"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0593 - acc: 0.9838\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY4wJy5KFMcaYsCxZGGOMCev/A+2nrsfIKvHsAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Error: 1.62%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM47sSHK5yMm",
        "colab_type": "text"
      },
      "source": [
        "# II. Perform SNIP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5Ye57FrfUYT",
        "colab_type": "code",
        "outputId": "47bcefc7-3f38-4fef-9f18-140733b5ac94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# create initial mask matrix (all ones), using LeNet ^^\n",
        "mask = []\n",
        "for layer in LeNet.trainable_weights:\n",
        "    #print(layer.shape)\n",
        "    mask.append(tf.Variable(np.ones(layer.shape),\n",
        "                            trainable = False,\n",
        "                            dtype = 'float32'))\n",
        "for i, _ in enumerate(mask):\n",
        "    print('Mask for layer ', i+1,':',sep='')\n",
        "    print(mask[i])\n",
        "\n",
        "LeNet_to_Prune = LeNet_300_100(img_size, num_classes,mask=mask)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mask for layer 1:\n",
            "<tf.Variable 'Variable:0' shape=(784, 300) dtype=float32_ref>\n",
            "Mask for layer 2:\n",
            "<tf.Variable 'Variable_1:0' shape=(300, 100) dtype=float32_ref>\n",
            "Mask for layer 3:\n",
            "<tf.Variable 'Variable_2:0' shape=(100, 10) dtype=float32_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8mbi9kO2Nio",
        "colab_type": "code",
        "outputId": "b5abf13b-4753-4b3a-c9b0-be9b3e7e9f38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Compute Gradient wrt Mask\n",
        "labels = y_train[:100] # mini-batch of 100 on MNIST from Experiment Setup Section\n",
        "loss = K.mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=LeNet_to_Prune.outputs))\n",
        "grads = K.gradients(loss, mask) # get gradient of loss wrt mask\n",
        "\n",
        "trainingExample = x_train[:100]\n",
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "evaluated_grads = sess.run(grads,feed_dict={LeNet_to_Prune.input:trainingExample})\n",
        "sess.close()\n",
        "\n",
        "print('Grads shape per layer')\n",
        "for layer in evaluated_grads:\n",
        "    print(layer.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Grads shape per layer\n",
            "(784, 300)\n",
            "(300, 100)\n",
            "(100, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdlZo_HqG859",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "64c66d67-686a-4524-b98f-50da5b8459ee"
      },
      "source": [
        "# convert grads to a dictionary for matrix pruning and reconstruction\n",
        "# each weight should have an associated key\n",
        "model_layers = []\n",
        "for index, layer in enumerate(evaluated_grads):\n",
        "    print('Shape of layer',index+1, '=', layer.shape)\n",
        "    #print(type(layer))\n",
        "    model_layers.append({key:abs(grad) for key, grad in np.ndenumerate(layer)})\n",
        "                         # key of a weight is its position in tuple form\n",
        "                         # note, absolute value is already taken here\n",
        "    print('sample grad value:', model_layers[index][(99,9)]) # sanity check\n",
        "    print('vectorized? ', np.array(list(model_layers[index].values())).shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of layer 1 = (784, 300)\n",
            "sample grad value: 4.1002355e-07\n",
            "vectorized?  (235200,)\n",
            "Shape of layer 2 = (300, 100)\n",
            "sample grad value: 2.4637693e-06\n",
            "vectorized?  (30000,)\n",
            "Shape of layer 3 = (100, 10)\n",
            "sample grad value: 6.622849e-06\n",
            "vectorized?  (1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KpyM1dJdrPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8bbbc7f1-f799-4304-f2ec-67119ca5db0b"
      },
      "source": [
        "# I. Normalize and get sensitivity per weight\n",
        "\n",
        "## 1. get sum of all grads\n",
        "sum_of_grads = 0\n",
        "for layer in model_layers: # layer = {(row, col) : grad_of_weight}\n",
        "    sum_in_layer = sum(layer.values())\n",
        "    #print(sum_in_layer)\n",
        "    sum_of_grads += sum_in_layer\n",
        "print('overall sum =',sum_of_grads)\n",
        "\n",
        "## 2. normalize each grad\n",
        "model_layers_normed = []\n",
        "for index, layer in enumerate(model_layers):\n",
        "    model_layers_normed.append({key:0 for key in layer.keys()})\n",
        "    for key in model_layers_normed[index].keys():\n",
        "        model_layers_normed[index][key] = layer[key]/sum_of_grads"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "overall sum = 0.6853408043732447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNbL_xYkAm6O",
        "colab_type": "code",
        "outputId": "59b2c3e0-ff30-45f3-e0d5-0c4b7286495c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# II. Get position of Top-K weights with highest sensitivity scores\n",
        "target_sparsity = 0.95 #(m-k)/m, where m is total params and k is non_zero w\n",
        "\n",
        "## x. Count total parameter values\n",
        "total_params = 0\n",
        "for i, layer_weights in enumerate(LeNet_to_Prune.trainable_weights):\n",
        "    total_params += int(np.prod(layer_weights.shape))\n",
        "print(\"# of total params =\",total_params)\n",
        "\n",
        "kappa = int(round(total_params * (1. - target_sparsity)))\n",
        "print(\"# of weights to keep =\", kappa)\n",
        "\n",
        "## x. SortDescending\n",
        "### concatenate the per layer dicts into 1 dict\n",
        "all_model_grads = {}\n",
        "for index, layer in enumerate(model_layers_normed):\n",
        "    all_model_grads.update({(index+1,) + key : grad for key, grad in layer.items()})\n",
        "                           # new key value = (layer,row,col)\n",
        "print('num of items =', len(all_model_grads))\n",
        "print('sample key:', list(all_model_grads.keys())[33] )\n",
        "print('sample value:', list(all_model_grads.values())[33])  \n",
        "print('check sum of all normed values = ',sum(all_model_grads.values()))\n",
        "\n",
        "### sort keys using values\n",
        "keys = list(all_model_grads.keys())\n",
        "values = list(all_model_grads.values())\n",
        "sorted_keys = sorted(all_model_grads.keys(), \n",
        "                     key=lambda k: all_model_grads[k],\n",
        "                     reverse = True)\n",
        "\n",
        "# get 1st k keys\n",
        "top_k_keys = sorted_keys[:kappa]\n",
        "\n",
        "# create mask of zeros\n",
        "pruning_mask = [] # list of np arrays\n",
        "for layer in evaluated_grads:\n",
        "    pruning_mask.append(np.zeros(layer.shape))\n",
        "    \n",
        "for i, _ in enumerate(pruning_mask):\n",
        "    print('Mask for layer ', i+1,':',sep='')\n",
        "    print(pruning_mask[i].shape)\n",
        "    \n",
        "# loop on the keys, and set mask value to 1\n",
        "for layer,row,col in top_k_keys:\n",
        "    pruning_mask[layer-1][row,col] = 1\n",
        "\n",
        "zero_norm = 0 # for sanity check\n",
        "for layer in pruning_mask:\n",
        "    zero_norm += np.sum(layer)\n",
        "print('zero norm =',zero_norm)\n",
        "print('kappa =', kappa)\n",
        "\n",
        "# convert to tf.Variable\n",
        "#for layer_mask in pruning_mask:\n",
        "#    pruning_mask = tf.Variable(layer_mask,\n",
        "#                              dtype = 'float32',\n",
        "#                              trainable=False)\n",
        "\n",
        "# determine if python is pass by ref, \n",
        "# if yes then change mask\n",
        "# if not re-init\n",
        "\n",
        "# filter\n",
        "# transform to mask(0,1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of total params = 266200\n",
            "# of weights to keep = 13310\n",
            "num of items = 266200\n",
            "sample key: (1, 0, 33)\n",
            "sample value: 0.0\n",
            "check sum of all normed values =  1.0000000000000113\n",
            "Mask for layer 1:\n",
            "(784, 300)\n",
            "Mask for layer 2:\n",
            "(300, 100)\n",
            "Mask for layer 3:\n",
            "(100, 10)\n",
            "zero norm = 13310.0\n",
            "kappa = 13310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp8C4II1wsPl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "be3f9292-c068-416e-f07c-db4f66162fee"
      },
      "source": [
        "# more desired to just modify the mask of previous model's layers, \n",
        "#    instead of creating new model with new mask.\n",
        "# if not possible to modify the masks, then create new model and just load\n",
        "#    weights of the previous model. So the mask is the only difference \n",
        "#    (not the initialization etc)\n",
        "\n",
        "Pruned_LeNet = LeNet_300_100(img_size, num_classes,mask=pruning_mask)\n",
        "Pruned_LeNet.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "prunable_dense_6 (PrunableDe (None, 300)               235200    \n",
            "_________________________________________________________________\n",
            "prunable_dense_7 (PrunableDe (None, 100)               30000     \n",
            "_________________________________________________________________\n",
            "prunable_dense_8 (PrunableDe (None, 10)                1000      \n",
            "=================================================================\n",
            "Total params: 266,200\n",
            "Trainable params: 266,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_CCdAMc7BQc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "9f841e20-493a-4d15-d3bf-2c8d76b7ff85"
      },
      "source": [
        "# setup Hyperparams\n",
        "SGDdizer = SGD(lr=0.1,\n",
        "               momentum = 0.9,\n",
        "               decay = 0.0005)\n",
        "Pruned_LeNet.compile(optimizer=SGDdizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "batch_size = 100\n",
        "epochs = 10\n",
        "    \n",
        "# fit model\n",
        "trainings = []\n",
        "\n",
        "start_time = time.time()\n",
        "trainings.append(Pruned_LeNet.fit(\n",
        "                  x_train, y_train,\n",
        "                  batch_size = batch_size,\n",
        "                  epochs = epochs,\n",
        "                  validation_data = (x_valid, y_valid)))\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "time.strftime(\"Total training time  = %H:%M:%S\", time.gmtime(elapsed_time))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/10\n",
            "54000/54000 [==============================] - 2s 39us/sample - loss: 0.5150 - acc: 0.8402 - val_loss: 0.1771 - val_acc: 0.9475\n",
            "Epoch 2/10\n",
            "54000/54000 [==============================] - 2s 38us/sample - loss: 0.1891 - acc: 0.9425 - val_loss: 0.1259 - val_acc: 0.9652\n",
            "Epoch 3/10\n",
            "54000/54000 [==============================] - 2s 38us/sample - loss: 0.1422 - acc: 0.9567 - val_loss: 0.1209 - val_acc: 0.9668\n",
            "Epoch 4/10\n",
            "54000/54000 [==============================] - 2s 37us/sample - loss: 0.1182 - acc: 0.9640 - val_loss: 0.1100 - val_acc: 0.9683\n",
            "Epoch 5/10\n",
            "54000/54000 [==============================] - 2s 38us/sample - loss: 0.1001 - acc: 0.9690 - val_loss: 0.1013 - val_acc: 0.9715\n",
            "Epoch 6/10\n",
            "54000/54000 [==============================] - 2s 38us/sample - loss: 0.0867 - acc: 0.9736 - val_loss: 0.1027 - val_acc: 0.9683\n",
            "Epoch 7/10\n",
            "54000/54000 [==============================] - 2s 39us/sample - loss: 0.0780 - acc: 0.9762 - val_loss: 0.1087 - val_acc: 0.9672\n",
            "Epoch 8/10\n",
            "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0706 - acc: 0.9780 - val_loss: 0.0944 - val_acc: 0.9722\n",
            "Epoch 9/10\n",
            "54000/54000 [==============================] - 2s 38us/sample - loss: 0.0647 - acc: 0.9808 - val_loss: 0.1002 - val_acc: 0.9722\n",
            "Epoch 10/10\n",
            "54000/54000 [==============================] - 2s 38us/sample - loss: 0.0599 - acc: 0.9817 - val_loss: 0.1025 - val_acc: 0.9728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Total training time  = 00:00:20'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNGBqEB21PQ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "1f5a154d-a9b9-4041-cf2c-904b9b397089"
      },
      "source": [
        "preds = Pruned_LeNet.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "plot_trainings(trainings)\n",
        "print(\"\\nTest Error: {:.2%}\\n\".format(1-preds[1])) # should get 1.65ish error"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 28us/sample - loss: 0.1033 - acc: 0.9689\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEkfjjQCmAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Error: 3.11%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r394XkHW1d-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}