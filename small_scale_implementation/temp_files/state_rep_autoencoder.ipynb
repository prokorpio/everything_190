{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wwzwgvVmax_-"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from models_to_prune import *\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torchvision.transforms as tf\n",
    "import torchvision.datasets as ds\n",
    "import torch.utils.data as data\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "W0zqCF0payAE",
    "outputId": "16186faa-a151-49ce-e57e-0eb9a9b62ceb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 : torch.Size([64, 3, 3, 3])\n",
      "pooled : torch.Size([64, 3])\n",
      "conv2 : torch.Size([128, 64, 3, 3])\n",
      "pooled : torch.Size([128, 64])\n",
      "conv3 : torch.Size([256, 128, 3, 3])\n",
      "pooled : torch.Size([256, 128])\n",
      "conv4 : torch.Size([512, 256, 3, 3])\n",
      "pooled : torch.Size([512, 256])\n",
      "tensor(-0.0003)\n"
     ]
    }
   ],
   "source": [
    "# See layer shapes\n",
    "cnn = BasicCNN()\n",
    "for name, layer in cnn.named_modules():\n",
    "    if 'conv' in name:\n",
    "        filters = layer.weight.data.clone()\n",
    "        print(name,':',filters.size())\n",
    "        # reduce last dim of 3x3 to 1x1 then squeeze\n",
    "        pooled_filter = torch.squeeze(F.avg_pool2d(filters,\n",
    "                                                   filters.size()[-1])) \n",
    "        pooled_filter = pooled_filter*1000 # scaling up the magnitudes \n",
    "        print(\"pooled :\",pooled_filter.size())\n",
    "\n",
    "# interpet 4d tensors as set of 3d blocks.  \n",
    "#print(pooled_filter[0])\n",
    "print(pooled_filter.cpu().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BPTbq-pDayAI"
   },
   "outputs": [],
   "source": [
    "# Create \"dataset\" of pooled layers\n",
    "# Convert set of 3d blocks to set of flat 2d maps. \n",
    "\n",
    "# Create pad-tensor container, same size as biggest layer\n",
    "filter_repeats = 10000 # each filter layer will be repeated this many times\n",
    "feat_size = 16  # size of 2d maps\n",
    "magnitude_scaler = 100\n",
    "state_rep = torch.zeros([filter_repeats, 512, feat_size,feat_size]) # set of N padded [512,16,16] \n",
    "                                                        # tensors for each of the 4 layers  \n",
    "for i in range(filter_repeats):\n",
    "    cnn = BasicCNN()\n",
    "    for name, layer in cnn.named_modules():\n",
    "        if 'conv' in name:\n",
    "            filters = layer.weight.data.clone()\n",
    "            pooled_filter = torch.squeeze(F.avg_pool2d(filters,\n",
    "                                                       filters.size()[-1]))\n",
    "            pooled_filter = pooled_filter*magnitude_scaler # scaling up the magnitudes \n",
    "            conv_layer_num = int(name[-1])\n",
    "            size = pooled_filter.size()\n",
    "            #if conv_layer_num == 1:\n",
    "            #    pads = (feat_size//2) - size[-1]//2\n",
    "            #    state_rep[i, :size[0], feat_size//2, pads-1 :-pads] = pooled_filter  # copy in center\n",
    "            #elif conv_layer_num == 2:\n",
    "            #    pads = (feat_size//2) - 4\n",
    "            #    state_rep[i+filter_repeats, :size[0], pads:-pads, pads:-pads] = pooled_filter.view(size[0],8,8)\n",
    "            #elif conv_layer_num == 3:\n",
    "            #    pads_r = (feat_size//2) - 4\n",
    "            #    pads_c = (feat_size//2) - 8\n",
    "            #    state_rep[i+filter_repeats*2, :size[0], :8, :16] = pooled_filter.view(size[0],8,16)\n",
    "            if conv_layer_num == 4:\n",
    "                state_rep[i] = pooled_filter.view(size[0],16,16) # same size as init state_rep\n",
    "                #state_rep[i+filter_repeats*3] = pooled_filter.view(size[0],16,16) # same size as init state_rep\n",
    "                #print(state_rep[i+filter_repeats*3][0])\n",
    "\n",
    "val_rep = filter_repeats//10\n",
    "validation = torch.zeros([val_rep*4, 512, feat_size,feat_size]) # set of N padded [512,16,16] \n",
    "                                                        # tensors for each of the 4 layers  \n",
    "for i in range(val_rep):\n",
    "    cnn = BasicCNN()\n",
    "    for name, layer in cnn.named_modules():\n",
    "        if 'conv' in name:\n",
    "            filters = layer.weight.data.clone()\n",
    "            pooled_filter = torch.squeeze(F.avg_pool2d(filters,\n",
    "                                                       filters.size()[-1]))\n",
    "            pooled_filter = pooled_filter*magnitude_scaler # scaling up the magnitudes \n",
    "            conv_layer_num = int(name[-1])\n",
    "            size = pooled_filter.size()\n",
    "            if conv_layer_num == 1:\n",
    "                pads = (feat_size//2) - size[-1]//2\n",
    "                validation[i, :size[0], feat_size//2, pads-1 :-pads] = pooled_filter  # copy in center\n",
    "            elif conv_layer_num == 2:\n",
    "                pads = (feat_size//2) - 4\n",
    "                validation[i+val_rep, :size[0], pads:-pads, pads:-pads] = pooled_filter.view(size[0],8,8)\n",
    "            elif conv_layer_num == 3:\n",
    "                pads_r = (feat_size//2) - 4\n",
    "                pads_c = (feat_size//2) - 8\n",
    "                validation[i+val_rep*2, :size[0], :8, :16] = pooled_filter.view(size[0],8,16)\n",
    "            elif conv_layer_num == 4:\n",
    "                validation[i+val_rep*3] = pooled_filter.view(size[0],16,16) # same size as init state_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "1z_Nn433ayAK",
    "outputId": "ee5199dc-0096-456d-e1c6-8896fb1e2884"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): Sigmoid()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (7): Sigmoid()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Flatten()\n",
      "    (10): Linear(in_features=1024, out_features=64, bias=True)\n",
      "  )\n",
      "  (latent_to_map): Linear(in_features=64, out_features=1024, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): ConvTranspose2d(64, 128, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (1): Sigmoid()\n",
      "    (2): ConvTranspose2d(128, 256, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (3): Sigmoid()\n",
      "    (4): ConvTranspose2d(256, 512, kernel_size=(6, 6), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build Autoencoder Class, modified from https://github.com/L1aoXingyu\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoding_dim = 64\n",
    "        self.encoder = nn.Sequential( # input size is [512,16,16]\n",
    "            nn.Conv2d(512, 256, 3),  # b, 256, 14, 14\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(4, stride=1),  # b, 256, 11, 11\n",
    "            nn.Conv2d(256, 128, 3),  # b, 128, 9, 9\n",
    "            \n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(3, stride=1),  # b, 128, 7, 7\n",
    "            nn.Conv2d(128, 64, 3),  # b, 64, 5, 5\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, stride=1),# b, 64, 4, 4\n",
    "\n",
    "            nn.Flatten(), #from dim=1 to -1\n",
    "            nn.Linear(64*4*4,self.encoding_dim)\n",
    "        )\n",
    "        \n",
    "        self.latent_to_map = nn.Linear(self.encoding_dim, 64*4*4)\n",
    "        self.decoder = nn.Sequential(    \n",
    "            nn.ConvTranspose2d(64, 128, 4, stride=1),  # b, 64,7,7\n",
    "            nn.Sigmoid(),\n",
    "            nn.ConvTranspose2d(128, 256, 5, stride=1),  # b, 256, 11, 11\n",
    "            nn.Sigmoid(),\n",
    "            nn.ConvTranspose2d(256, 512, 6),  # b, 512, 16, 16\n",
    "          #  nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.latent_to_map(x).view(-1,64,4,4) \n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "model = autoencoder().cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 939
    },
    "colab_type": "code",
    "id": "9dmjgKJCbUMC",
    "outputId": "ffb54d14-0af3-4740-9d08-c6b464bb3195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/10], loss:0.3417483866214752, val_loss:1.3761440515518188, rand_loss:0.5805090665817261\n",
      "epoch [1/10], loss:0.33293068408966064, val_loss:0.16735203564167023, rand_loss:0.5801882743835449\n",
      "epoch [1/10], loss:0.3233155310153961, val_loss:0.13830313086509705, rand_loss:0.5806146264076233\n",
      "epoch [1/10], loss:0.3228972852230072, val_loss:0.13621152937412262, rand_loss:0.5800780653953552\n",
      "epoch [1/10], loss:0.3225247263908386, val_loss:0.13382185995578766, rand_loss:0.5803004503250122\n",
      "epoch [1/10], loss:0.3219667673110962, val_loss:0.13134582340717316, rand_loss:0.580004870891571\n",
      "epoch [1/10], loss:0.32168716192245483, val_loss:0.1291329562664032, rand_loss:0.5801371932029724\n",
      "epoch [1/10], loss:0.32225286960601807, val_loss:0.12731145322322845, rand_loss:0.5809592008590698\n",
      "epoch [1/10], loss:0.32205507159233093, val_loss:0.1259191930294037, rand_loss:0.5805268883705139\n",
      "epoch [1/10], loss:0.32172659039497375, val_loss:0.12491466850042343, rand_loss:0.5807982087135315\n",
      "epoch [1/10], loss:0.32194849848747253, val_loss:0.1242263913154602, rand_loss:0.5805700421333313\n",
      "epoch [1/10], loss:0.3221557140350342, val_loss:0.12376321107149124, rand_loss:0.5804152488708496\n",
      "epoch [1/10], loss:0.321880578994751, val_loss:0.12345761060714722, rand_loss:0.5803701877593994\n",
      "epoch [1/10], loss:0.32179781794548035, val_loss:0.12325238436460495, rand_loss:0.5800889730453491\n",
      "epoch [1/10], loss:0.3217727541923523, val_loss:0.12311168760061264, rand_loss:0.5803280472755432\n",
      "epoch [1/10], loss:0.32169175148010254, val_loss:0.12301301211118698, rand_loss:0.5803384780883789\n",
      "epoch [1/10], loss:0.3216724395751953, val_loss:0.12293880432844162, rand_loss:0.5800679922103882\n",
      "epoch [1/10], loss:0.3216784596443176, val_loss:0.12287145853042603, rand_loss:0.580451250076294\n",
      "epoch [1/10], loss:0.32163870334625244, val_loss:0.12281637638807297, rand_loss:0.580285906791687\n",
      "epoch [1/10], loss:0.32156577706336975, val_loss:0.1227715015411377, rand_loss:0.5801142454147339\n",
      "epoch [1/10], loss:0.3216061592102051, val_loss:0.12272511422634125, rand_loss:0.5803765058517456\n",
      "epoch [1/10], loss:0.32173630595207214, val_loss:0.12268009036779404, rand_loss:0.580035924911499\n",
      "epoch [1/10], loss:0.3219035863876343, val_loss:0.12263844162225723, rand_loss:0.5804972648620605\n",
      "epoch [1/10], loss:0.32161155343055725, val_loss:0.12261851131916046, rand_loss:0.580112099647522\n",
      "epoch [1/10], loss:0.321464866399765, val_loss:0.12259373068809509, rand_loss:0.5801562070846558\n",
      "epoch [1/10], loss:0.32145994901657104, val_loss:0.12255093455314636, rand_loss:0.5803244113922119\n",
      "epoch [1/10], loss:0.3216885030269623, val_loss:0.12252577394247055, rand_loss:0.5803537964820862\n",
      "epoch [1/10], loss:0.32183510065078735, val_loss:0.12250925600528717, rand_loss:0.5800981521606445\n",
      "epoch [1/10], loss:0.3216492533683777, val_loss:0.12248299270868301, rand_loss:0.5805873274803162\n",
      "epoch [1/10], loss:0.3219309449195862, val_loss:0.12246257811784744, rand_loss:0.5801219940185547\n",
      "epoch [1/10], loss:0.32149165868759155, val_loss:0.12244944274425507, rand_loss:0.5802165865898132\n",
      "epoch [1/10], loss:0.3218345642089844, val_loss:0.12243341654539108, rand_loss:0.5802851319313049\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-2fd2f92a7064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mave_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mval_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 16\n",
    "learning_rate = 1e-3\n",
    "\n",
    "state_rep = state_rep.to(device)\n",
    "train_dl = DataLoader(state_rep, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(validation, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = autoencoder().cuda()\n",
    "MSE_criterion = nn.MSELoss()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "                                                # removed weight_decay=1e-5\n",
    "#sample = iter(train_dl).next()\n",
    "#print(sample.cpu().mean())\n",
    "#raise KeyboardInterrupt\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(train_dl):\n",
    "        model.train()\n",
    "        data = Variable(data).cuda()\n",
    "        # ===================forward=====================\n",
    "        output = model(data)\n",
    "        #loss = torch.sum(torch.log(torch.cosh(data-output)))\n",
    "        loss = torch.mean(torch.abs(data-output)) # MAE criterion\n",
    "        rand_loss = torch.mean(torch.abs(data-torch.rand_like(output))) # sanity check\n",
    "        #loss = MSE_criterion(output, data)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "         # ===================log========================\n",
    "        if i % 100 == 0:\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            num_batches = 0\n",
    "            ave_val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for val in valid_dl:\n",
    "                    val = Variable(val).cuda()\n",
    "                    val_output = model(val)\n",
    "                    #val_loss += torch.sum(torch.log(torch.cosh(val-val_output)))\n",
    "                    val_loss += torch.mean(torch.abs(val - val_output))\n",
    "                    #val_loss += MSE_criterion(val_output,val)\n",
    "                    num_batches += 1\n",
    "                ave_val_loss = val_loss/num_batches\n",
    "\n",
    "\n",
    "            print('epoch [{}/{}], loss:{}, val_loss:{}, rand_loss:{}'\n",
    "                .format(epoch+1, num_epochs, loss.item(), ave_val_loss, rand_loss.item()))\n",
    "            torch.save(model.state_dict(), './conv_autoencoder.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8AyOdWhXayAM",
    "outputId": "c2599daa-7f26-4245-d524-6dce5e62736c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64])\n",
      "0.32188737392425537\n",
      "0.1608814299106598\n",
      "tensor([[ 4.7312e-04, -3.1684e-03, -7.4903e-03, -1.1314e-02, -9.6496e-03,\n",
      "         -1.9540e-03,  7.4072e-04,  1.4077e-03,  1.4146e-03,  6.4284e-04,\n",
      "         -1.5436e-03, -4.9544e-03, -1.0017e-02, -1.0930e-02, -7.3620e-03,\n",
      "          8.1505e-04],\n",
      "        [ 4.0795e-03, -6.8054e-04, -3.8856e-03, -2.0285e-03, -3.2532e-03,\n",
      "          6.8349e-05,  1.7160e-03,  1.7578e-03,  1.9269e-03,  2.1727e-03,\n",
      "          2.3942e-03, -2.9430e-03, -3.2713e-03, -2.5106e-03, -3.0127e-03,\n",
      "          8.1690e-04],\n",
      "        [ 2.2640e-03, -1.9204e-03,  1.5189e-03,  3.6689e-03,  5.8935e-04,\n",
      "         -8.4727e-03, -6.0117e-04,  1.1800e-03,  1.4967e-03,  1.2836e-03,\n",
      "          1.1956e-03, -1.1914e-03,  4.4918e-03,  2.1104e-03, -1.2721e-03,\n",
      "         -7.8899e-03],\n",
      "        [-5.4507e-03,  4.9092e-03,  3.1393e-03, -3.2788e-03,  5.4446e-03,\n",
      "         -2.4567e-03,  1.1063e-03,  1.5781e-03,  1.3962e-03,  1.4433e-04,\n",
      "         -4.5205e-03,  6.4411e-03,  1.4911e-03, -1.0902e-03,  5.7262e-03,\n",
      "         -3.9011e-03],\n",
      "        [-2.8442e-03,  4.4944e-03,  6.5295e-03, -3.7933e-03, -1.0420e-03,\n",
      "          5.3576e-04,  1.8256e-03,  1.7001e-03,  1.5384e-03,  7.6858e-04,\n",
      "         -2.1952e-03,  7.3985e-03,  4.1869e-03, -5.5862e-03,  4.1078e-05,\n",
      "          1.6798e-03],\n",
      "        [ 4.3620e-03,  5.3524e-03,  5.5689e-03,  2.7773e-03,  1.2063e-04,\n",
      "          9.7364e-03,  3.5694e-03,  2.2469e-03,  2.2325e-03,  3.0177e-03,\n",
      "          5.6922e-03,  6.2593e-03,  5.9192e-03,  2.1723e-03,  1.4766e-03,\n",
      "          9.6816e-03],\n",
      "        [ 2.5332e-03,  2.4795e-03,  2.5446e-03,  1.7705e-03,  1.7237e-03,\n",
      "          3.6482e-03,  1.9108e-03,  1.8110e-03,  1.8101e-03,  1.8584e-03,\n",
      "          2.4998e-03,  2.8721e-03,  2.9575e-03,  1.6382e-03,  1.3737e-03,\n",
      "          3.4099e-03],\n",
      "        [ 1.9117e-03,  1.8839e-03,  1.7998e-03,  1.6377e-03,  1.6851e-03,\n",
      "          2.1238e-03,  1.8097e-03,  1.8049e-03,  1.8049e-03,  1.8065e-03,\n",
      "          1.8499e-03,  1.9967e-03,  1.9667e-03,  1.6807e-03,  1.6530e-03,\n",
      "          2.0883e-03],\n",
      "        [ 1.6927e-03,  1.5778e-03,  1.2341e-03,  1.0750e-03,  1.1980e-03,\n",
      "          1.6151e-03,  1.7977e-03,  1.8046e-03,  1.8046e-03,  1.7978e-03,\n",
      "          1.6553e-03,  1.5289e-03,  1.2071e-03,  1.1828e-03,  1.2513e-03,\n",
      "          1.6836e-03],\n",
      "        [ 1.4033e-03,  5.3272e-04, -5.3644e-04, -1.0208e-03, -7.5118e-04,\n",
      "          6.1840e-04,  1.7050e-03,  1.7945e-03,  1.7967e-03,  1.7228e-03,\n",
      "          1.2361e-03,  4.7050e-04, -7.3537e-04, -7.2367e-04, -6.5843e-04,\n",
      "          1.1295e-03],\n",
      "        [ 7.3709e-04, -3.0786e-03, -7.9070e-03, -1.0656e-02, -1.1111e-02,\n",
      "         -4.8055e-03,  2.6897e-04,  1.3541e-03,  1.3778e-03,  6.3078e-04,\n",
      "         -9.0882e-04, -5.8593e-03, -1.0514e-02, -1.0885e-02, -7.9836e-03,\n",
      "         -3.5225e-04],\n",
      "        [ 2.2535e-03, -1.6022e-03, -1.2425e-03,  5.5695e-04, -3.2507e-04,\n",
      "         -1.9031e-03,  1.8372e-03,  1.8805e-03,  2.0217e-03,  2.4075e-03,\n",
      "          3.2042e-03, -3.7346e-04, -6.7711e-04,  8.0555e-04, -7.9741e-04,\n",
      "         -1.2903e-03],\n",
      "        [-1.2470e-03, -2.8724e-04,  3.8623e-03,  2.5273e-03,  3.9525e-03,\n",
      "         -9.0059e-03, -7.7647e-04,  1.1450e-03,  1.6106e-03,  1.2887e-03,\n",
      "         -5.2635e-04,  1.5228e-03,  4.9416e-03,  2.0860e-03,  7.7796e-04,\n",
      "         -7.6096e-03],\n",
      "        [-6.4435e-03,  7.0374e-03,  4.2999e-03, -5.1078e-03,  4.2165e-03,\n",
      "         -8.6961e-04,  7.0536e-04,  1.4580e-03,  1.3786e-03,  1.0760e-04,\n",
      "         -5.4822e-03,  8.7683e-03,  2.4708e-03, -3.4176e-03,  5.9871e-03,\n",
      "          6.6787e-04],\n",
      "        [-3.1724e-04,  5.8711e-03,  7.0305e-03, -2.3223e-03, -3.3304e-03,\n",
      "          3.9283e-03,  1.8686e-03,  1.7985e-03,  1.5584e-03,  1.0980e-03,\n",
      "          6.8580e-04,  7.8567e-03,  5.3870e-03, -3.6385e-03, -2.0409e-03,\n",
      "          6.3546e-03],\n",
      "        [ 5.8571e-03,  4.4847e-03,  4.2228e-03,  4.2657e-03,  4.3505e-04,\n",
      "          1.1065e-02,  4.1267e-03,  2.4409e-03,  2.2861e-03,  3.0716e-03,\n",
      "          5.9666e-03,  4.2951e-03,  4.1789e-03,  4.1305e-03,  1.4904e-03,\n",
      "          1.0911e-02]], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "loaded_model = autoencoder().cuda()\n",
    "checkpoint_dict = torch.load('conv_autoencoder.pth')\n",
    "loaded_model.load_state_dict(checkpoint_dict)\n",
    "\n",
    "encoded_states = loaded_model.encoder(data)\n",
    "print(encoded_states.size())\n",
    "#print(encoded_states[1])\n",
    "output_ = loaded_model(data)\n",
    "MAE_loss = torch.mean(torch.abs(data-output))\n",
    "MSE_loss = MSE_criterion(output, data)\n",
    "print(MAE_loss.item())\n",
    "print(MSE_loss.item())\n",
    "print(output[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "X5OqCyq_ayAP",
    "outputId": "22fcba23-c153-4457-a2ca-ac8548654b19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250.0"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4000/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wlUmhBU1ayAS",
    "outputId": "15f8654a-fe8a-4884-9cca-c6577b168228"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 512, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "print(validation.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o8tHWKdBayAU",
    "outputId": "f95cad21-b08b-4002-f298-2aab169fe2f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7162978701990245"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tanh(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "state_rep_autoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch_venv",
   "language": "python",
   "name": "torch_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
