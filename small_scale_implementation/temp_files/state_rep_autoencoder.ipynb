{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "torch_venv",
      "language": "python",
      "name": "torch_venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "state_rep.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwzwgvVmax_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Libraries\n",
        "from models_to_prune import *\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torchvision.transforms as tf\n",
        "import torchvision.datasets as ds\n",
        "import torch.utils.data as data\n",
        "\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0zqCF0payAE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f1d6a67a-4582-4b4c-d0b9-adee969a8ff3"
      },
      "source": [
        "# See layer shapes\n",
        "cnn = BasicCNN()\n",
        "for name, layer in cnn.named_modules():\n",
        "    if 'conv' in name:\n",
        "        filters = layer.weight.data.clone()\n",
        "        print(name,':',filters.size())\n",
        "        pooled_filter = torch.squeeze(F.avg_pool2d(filters,\n",
        "                                                   filters.size()[-1]))\n",
        "        print(\"pooled :\",pooled_filter.size())\n",
        "\n",
        "# interpet 4d tensors as set of 3d blocks.  "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1 : torch.Size([64, 3, 3, 3])\n",
            "pooled : torch.Size([64, 3])\n",
            "conv2 : torch.Size([128, 64, 3, 3])\n",
            "pooled : torch.Size([128, 64])\n",
            "conv3 : torch.Size([256, 128, 3, 3])\n",
            "pooled : torch.Size([256, 128])\n",
            "conv4 : torch.Size([512, 256, 3, 3])\n",
            "pooled : torch.Size([512, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPTbq-pDayAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create \"dataset\" of pooled layers\n",
        "# Convert set of 3d blocks to set of flat 2d maps. \n",
        "\n",
        "# Create pad-tensor container, same size as biggest layer\n",
        "filter_repeats = 1000 # each filter layer will be repeated this many times\n",
        "feat_size = 16  # size of 2d maps\n",
        "state_rep = torch.zeros([filter_repeats, 512, feat_size,feat_size]) # set of N padded [512,16,16] \n",
        "                                                        # tensors for each of the 4 layers  \n",
        "for i in range(filter_repeats):\n",
        "    cnn = BasicCNN()\n",
        "    for name, layer in cnn.named_modules():\n",
        "        if 'conv' in name:\n",
        "            filters = layer.weight.data.clone()\n",
        "            pooled_filter = torch.squeeze(F.avg_pool2d(filters,\n",
        "                                                       filters.size()[-1]))\n",
        "            conv_layer_num = int(name[-1])\n",
        "            size = pooled_filter.size()\n",
        "            #if conv_layer_num == 1:\n",
        "            #    pads = (feat_size//2) - size[-1]//2\n",
        "            #    state_rep[i, :size[0], feat_size//2, pads-1 :-pads] = pooled_filter  # copy in center\n",
        "            #elif conv_layer_num == 2:\n",
        "            #    pads = (feat_size//2) - 4\n",
        "            #    state_rep[i+filter_repeats, :size[0], pads:-pads, pads:-pads] = pooled_filter.view(size[0],8,8)\n",
        "            #elif conv_layer_num == 3:\n",
        "            #    pads_r = (feat_size//2) - 4\n",
        "            #    pads_c = (feat_size//2) - 8\n",
        "            #    state_rep[i+filter_repeats*2, :size[0], :8, :16] = pooled_filter.view(size[0],8,16)\n",
        "            if conv_layer_num == 4:\n",
        "                state_rep[i] = pooled_filter.view(size[0],16,16) # same size as init state_rep\n",
        "                #state_rep[i+filter_repeats*3] = pooled_filter.view(size[0],16,16) # same size as init state_rep\n",
        "                #print(state_rep[i+filter_repeats*3][0])\n",
        "\n",
        "val_rep = filter_repeats//10\n",
        "validation = torch.zeros([val_rep*4, 512, feat_size,feat_size]) # set of N padded [512,16,16] \n",
        "                                                        # tensors for each of the 4 layers  \n",
        "for i in range(val_reps):\n",
        "    cnn = BasicCNN()\n",
        "    for name, layer in cnn.named_modules():\n",
        "        if 'conv' in name:\n",
        "            filters = layer.weight.data.clone()\n",
        "            pooled_filter = torch.squeeze(F.avg_pool2d(filters,\n",
        "                                                       filters.size()[-1]))\n",
        "            conv_layer_num = int(name[-1])\n",
        "            size = pooled_filter.size()\n",
        "            if conv_layer_num == 1:\n",
        "                pads = (feat_size//2) - size[-1]//2\n",
        "                validation[i, :size[0], feat_size//2, pads-1 :-pads] = pooled_filter  # copy in center\n",
        "            elif conv_layer_num == 2:\n",
        "                pads = (feat_size//2) - 4\n",
        "                validation[i+val_rep, :size[0], pads:-pads, pads:-pads] = pooled_filter.view(size[0],8,8)\n",
        "            elif conv_layer_num == 3:\n",
        "                pads_r = (feat_size//2) - 4\n",
        "                pads_c = (feat_size//2) - 8\n",
        "                validation[i+val_rep*2, :size[0], :8, :16] = pooled_filter.view(size[0],8,16)\n",
        "            elif conv_layer_num == 4:\n",
        "                validation[i+val_rep*3] = pooled_filter.view(size[0],16,16) # same size as init state_rep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z_Nn433ayAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build Autoencoder Class, modified from https://github.com/L1aoXingyu\n",
        "\n",
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential( # input size is [512,16,16]\n",
        "            nn.Conv2d(512, 64, 3),  # b, 64, 14, 14\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(4, stride=2),  # b, 64, 6, 6\n",
        "            nn.Conv2d(64, 16, 3),  # b, 16, 4, 4\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, stride=1),  # b, 16, 3, 3\n",
        "            nn.Flatten(), #from dim=1 to -1\n",
        "            nn.Linear(16*3*3,100)\n",
        "        )\n",
        "        \n",
        "        self.latent_to_map = nn.Linear(100, 16*3*3)\n",
        "        self.decoder = nn.Sequential(    \n",
        "            nn.ConvTranspose2d(16, 64, 3, stride=1),  # b, 64,4,4 \n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, 256, 5, stride=2),  # b, 256, 10, 10\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 512, 4),  # b, 512, 16, 16\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.latent_to_map(x).view(-1,16,3,3) \n",
        "        x = self.decoder(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dmjgKJCbUMC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "cc4f6022-ec6d-4739-a1a5-e4e169d54db1"
      },
      "source": [
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "learning_rate = 1e-3\n",
        "\n",
        "state_rep = state_rep.to(device)\n",
        "train_dl = DataLoader(state_rep, batch_size=batch_size, shuffle=True)\n",
        "valid_dl = DataLoader(validation, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model = autoencoder().cuda()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\n",
        "                             weight_decay=1e-5)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(train_dl):\n",
        "        model.train()\n",
        "        data = Variable(data).cuda()\n",
        "        # ===================forward=====================\n",
        "        output = model(data)\n",
        "        loss = criterion(output, data)\n",
        "        # ===================backward====================\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "         # ===================log========================\n",
        "        if i % 1 == 0:\n",
        "            model.eval()\n",
        "            val_loss = 0\n",
        "            num_batches = 0\n",
        "            ave_val_loss = 0\n",
        "            with torch.no_grad():\n",
        "                for val in valid_dl:\n",
        "                    val = Variable(val).cuda()\n",
        "                    val_output = model(val)\n",
        "                    val_loss += criterion(val_output,val)\n",
        "                    num_batches += 1\n",
        "                ave_val_loss = val_loss/num_batches\n",
        "\n",
        "\n",
        "            print('epoch [{}/{}], loss:{}, val_loss:{}'\n",
        "                .format(epoch+1, num_epochs, loss.item(), ave_val_loss))\n",
        "\n",
        "torch.save(model.state_dict(), './conv_autoencoder.pth')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch [1/10], loss:5.780967330792919e-05, val_loss:1.929750396811869e-05\n",
            "epoch [1/10], loss:2.7832160412799567e-05, val_loss:1.26446939248126e-05\n",
            "epoch [1/10], loss:2.1137650037417188e-05, val_loss:1.1772473953897133e-05\n",
            "epoch [1/10], loss:2.022811895585619e-05, val_loss:1.1493663805595133e-05\n",
            "epoch [1/10], loss:2.005392343562562e-05, val_loss:1.0184913662669715e-05\n",
            "epoch [1/10], loss:1.872719258244615e-05, val_loss:9.423513802175876e-06\n",
            "epoch [1/10], loss:1.8009019186138175e-05, val_loss:9.48896831687307e-06\n",
            "epoch [1/10], loss:1.8074239051202312e-05, val_loss:9.104628588829655e-06\n",
            "epoch [1/10], loss:1.772091127349995e-05, val_loss:8.566620635974687e-06\n",
            "epoch [1/10], loss:1.712510857032612e-05, val_loss:8.14661143522244e-06\n",
            "epoch [1/10], loss:1.6748643247410655e-05, val_loss:8.111560418910813e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-6de6b4ce0a21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mval_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                     \u001b[0mval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                     \u001b[0mnum_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mave_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2202\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2204\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2205\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AyOdWhXayAM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12975699-a577-49d8-d800-04053cc46a80"
      },
      "source": [
        "Win = 10 \n",
        "stride = 1\n",
        "kernel = 8\n",
        "(Win-1)*stride + kernel-1"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5OqCyq_ayAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22fcba23-c153-4457-a2ca-ac8548654b19"
      },
      "source": [
        "4000/16"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlUmhBU1ayAS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15f8654a-fe8a-4884-9cca-c6577b168228"
      },
      "source": [
        "print(validation.size())\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([400, 512, 16, 16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8tHWKdBayAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}