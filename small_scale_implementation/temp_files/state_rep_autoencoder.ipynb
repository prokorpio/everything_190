{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "torch_venv",
      "language": "python",
      "name": "torch_venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "state_rep.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwzwgvVmax_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Libraries\n",
        "from models_to_prune import *\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torchvision.transforms as tf\n",
        "import torchvision.datasets as ds\n",
        "import torch.utils.data as data\n",
        "\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0zqCF0payAE",
        "colab_type": "code",
        "outputId": "a716a8d3-7588-42b8-c967-ec1d623832b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# See layer shapes\n",
        "cnn = BasicCNN()\n",
        "for name, layer in cnn.named_modules():\n",
        "    if 'conv' in name:\n",
        "        filters = layer.weight.data.clone()\n",
        "        print(name,':',filters.size())\n",
        "        # reduce last dim of 3x3 to 1x1 then squeeze\n",
        "        pooled_filter = torch.squeeze(F.avg_pool2d(filters,\n",
        "                                                   filters.size()[-1])) \n",
        "        pooled_filter = pooled_filter*100 # scaling up the magnitudes \n",
        "        print(\"pooled :\",pooled_filter.size())\n",
        "\n",
        "# interpet 4d tensors as set of 3d blocks.  \n",
        "#print(pooled_filter[0])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1 : torch.Size([64, 3, 3, 3])\n",
            "pooled : torch.Size([64, 3])\n",
            "conv2 : torch.Size([128, 64, 3, 3])\n",
            "pooled : torch.Size([128, 64])\n",
            "conv3 : torch.Size([256, 128, 3, 3])\n",
            "pooled : torch.Size([256, 128])\n",
            "conv4 : torch.Size([512, 256, 3, 3])\n",
            "pooled : torch.Size([512, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPTbq-pDayAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create \"dataset\" of pooled layers\n",
        "# Convert set of 3d blocks to set of flat 2d maps. \n",
        "\n",
        "# Create pad-tensor container, same size as biggest layer\n",
        "filter_repeats = 10000 # each filter layer will be repeated this many times\n",
        "feat_size = 16  # size of 2d maps\n",
        "state_rep = torch.zeros([filter_repeats, 512, feat_size,feat_size]) # set of N padded [512,16,16] \n",
        "                                                        # tensors for each of the 4 layers  \n",
        "for i in range(filter_repeats):\n",
        "    cnn = BasicCNN()\n",
        "    for name, layer in cnn.named_modules():\n",
        "        if 'conv' in name:\n",
        "            filters = layer.weight.data.clone()\n",
        "            pooled_filter = torch.squeeze(F.avg_pool2d(filters,\n",
        "                                                       filters.size()[-1]))\n",
        "            pooled_filter = pooled_filter*100 # scaling up the magnitudes \n",
        "            conv_layer_num = int(name[-1])\n",
        "            size = pooled_filter.size()\n",
        "            #if conv_layer_num == 1:\n",
        "            #    pads = (feat_size//2) - size[-1]//2\n",
        "            #    state_rep[i, :size[0], feat_size//2, pads-1 :-pads] = pooled_filter  # copy in center\n",
        "            #elif conv_layer_num == 2:\n",
        "            #    pads = (feat_size//2) - 4\n",
        "            #    state_rep[i+filter_repeats, :size[0], pads:-pads, pads:-pads] = pooled_filter.view(size[0],8,8)\n",
        "            #elif conv_layer_num == 3:\n",
        "            #    pads_r = (feat_size//2) - 4\n",
        "            #    pads_c = (feat_size//2) - 8\n",
        "            #    state_rep[i+filter_repeats*2, :size[0], :8, :16] = pooled_filter.view(size[0],8,16)\n",
        "            if conv_layer_num == 4:\n",
        "                state_rep[i] = pooled_filter.view(size[0],16,16) # same size as init state_rep\n",
        "                #state_rep[i+filter_repeats*3] = pooled_filter.view(size[0],16,16) # same size as init state_rep\n",
        "                #print(state_rep[i+filter_repeats*3][0])\n",
        "\n",
        "val_rep = filter_repeats//10\n",
        "validation = torch.zeros([val_rep*4, 512, feat_size,feat_size]) # set of N padded [512,16,16] \n",
        "                                                        # tensors for each of the 4 layers  \n",
        "for i in range(val_rep):\n",
        "    cnn = BasicCNN()\n",
        "    for name, layer in cnn.named_modules():\n",
        "        if 'conv' in name:\n",
        "            filters = layer.weight.data.clone()\n",
        "            pooled_filter = torch.squeeze(F.avg_pool2d(filters,\n",
        "                                                       filters.size()[-1]))\n",
        "            pooled_filter = pooled_filter*100 # scaling up the magnitudes \n",
        "            conv_layer_num = int(name[-1])\n",
        "            size = pooled_filter.size()\n",
        "            if conv_layer_num == 1:\n",
        "                pads = (feat_size//2) - size[-1]//2\n",
        "                validation[i, :size[0], feat_size//2, pads-1 :-pads] = pooled_filter  # copy in center\n",
        "            elif conv_layer_num == 2:\n",
        "                pads = (feat_size//2) - 4\n",
        "                validation[i+val_rep, :size[0], pads:-pads, pads:-pads] = pooled_filter.view(size[0],8,8)\n",
        "            elif conv_layer_num == 3:\n",
        "                pads_r = (feat_size//2) - 4\n",
        "                pads_c = (feat_size//2) - 8\n",
        "                validation[i+val_rep*2, :size[0], :8, :16] = pooled_filter.view(size[0],8,16)\n",
        "            elif conv_layer_num == 4:\n",
        "                validation[i+val_rep*3] = pooled_filter.view(size[0],16,16) # same size as init state_rep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z_Nn433ayAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build Autoencoder Class, modified from https://github.com/L1aoXingyu\n",
        "\n",
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential( # input size is [512,16,16]\n",
        "            nn.Conv2d(512, 64, 3),  # b, 64, 14, 14\n",
        "            nn.Sigmoid(),\n",
        "            #nn.ReLU(True),\n",
        "            nn.MaxPool2d(4, stride=2),  # b, 64, 6, 6\n",
        "            nn.Conv2d(64, 16, 3),  # b, 16, 4, 4\n",
        "            #nn.ReLU(True),\n",
        "            nn.Sigmoid(),\n",
        "            nn.MaxPool2d(2, stride=1),  # b, 16, 3, 3\n",
        "            nn.Flatten(), #from dim=1 to -1\n",
        "            nn.Linear(16*3*3,100)\n",
        "        )\n",
        "        \n",
        "        self.latent_to_map = nn.Linear(100, 16*3*3)\n",
        "        self.decoder = nn.Sequential(    \n",
        "            nn.ConvTranspose2d(16, 64, 3, stride=1),  # b, 64,4,4 \n",
        "            nn.Sigmoid(),\n",
        "            #nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, 256, 5, stride=2),  # b, 256, 10, 10\n",
        "            nn.Sigmoid(),\n",
        "            #nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 512, 4),  # b, 512, 16, 16\n",
        "          #  nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.latent_to_map(x).view(-1,16,3,3) \n",
        "        x = self.decoder(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dmjgKJCbUMC",
        "colab_type": "code",
        "outputId": "4b36f247-a12a-409c-8447-8b8c08330ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        }
      },
      "source": [
        "num_epochs = 100\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3\n",
        "\n",
        "state_rep = state_rep.to(device)\n",
        "train_dl = DataLoader(state_rep, batch_size=batch_size, shuffle=True)\n",
        "valid_dl = DataLoader(validation, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model = autoencoder().cuda()\n",
        "MSE_criterion = nn.MSELoss()\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(train_dl):\n",
        "        model.train()\n",
        "        data = Variable(data).cuda()\n",
        "        # ===================forward=====================\n",
        "        output = model(data)\n",
        "        #loss = torch.sum(torch.log(torch.cosh(data-output)))\n",
        "        loss = torch.mean(torch.abs(data-output)) # MAE criterion\n",
        "        #loss = MSE_criterion(output, data)\n",
        "        # ===================backward====================\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "         # ===================log========================\n",
        "        if i % 100 == 0:\n",
        "            model.eval()\n",
        "            val_loss = 0\n",
        "            num_batches = 0\n",
        "            ave_val_loss = 0\n",
        "            with torch.no_grad():\n",
        "                for val in valid_dl:\n",
        "                    val = Variable(val).cuda()\n",
        "                    val_output = model(val)\n",
        "                    #val_loss += torch.sum(torch.log(torch.cosh(val-val_output)))\n",
        "                    val_loss += torch.mean(torch.abs(val - val_output))\n",
        "                    #val_loss += MSE_criterion(val_output,val)\n",
        "                    num_batches += 1\n",
        "                ave_val_loss = val_loss/num_batches\n",
        "\n",
        "\n",
        "            print('epoch [{}/{}], loss:{}, val_loss:{}'\n",
        "                .format(epoch+1, num_epochs, loss.item(), ave_val_loss))\n",
        "            torch.save(model.state_dict(), './conv_autoencoder.pth')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch [1/100], loss:0.34705641865730286, val_loss:1.1203267574310303\n",
            "epoch [1/100], loss:0.32168132066726685, val_loss:0.12323831021785736\n",
            "epoch [2/100], loss:0.32164719700813293, val_loss:0.12233477085828781\n",
            "epoch [2/100], loss:0.3215946555137634, val_loss:0.1222018450498581\n",
            "epoch [3/100], loss:0.3217010498046875, val_loss:0.12224549800157547\n",
            "epoch [3/100], loss:0.3217606544494629, val_loss:0.12233451753854752\n",
            "epoch [4/100], loss:0.32168132066726685, val_loss:0.12319160252809525\n",
            "epoch [4/100], loss:0.321719765663147, val_loss:0.12320737540721893\n",
            "epoch [5/100], loss:0.321804016828537, val_loss:0.12415535002946854\n",
            "epoch [5/100], loss:0.32189255952835083, val_loss:0.12433242052793503\n",
            "epoch [6/100], loss:0.3218381404876709, val_loss:0.12538471817970276\n",
            "epoch [6/100], loss:0.32175806164741516, val_loss:0.12546184659004211\n",
            "epoch [7/100], loss:0.3216565251350403, val_loss:0.12665827572345734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-10958ba80907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                     \u001b[0mval_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0;31m#val_loss += torch.sum(torch.log(torch.cosh(val-val_output)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AyOdWhXayAM",
        "colab_type": "code",
        "outputId": "545b22e3-111c-4290-dd32-1cef3e000587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "loaded_model = autoencoder().cuda()\n",
        "checkpoint_dict = torch.load('conv_autoencoder.pth')\n",
        "loaded_model.load_state_dict(checkpoint_dict)\n",
        "\n",
        "encoded_states = loaded_model.encoder(data)\n",
        "print(encoded_states.size())\n",
        "print(encoded_states[1])\n",
        "output_ = loaded_model(data)\n",
        "MAE_loss = torch.mean(torch.abs(data-output))\n",
        "MSE_loss = MSE_criterion(output, data)\n",
        "print(MAE_loss.item())\n",
        "print(MSE_loss.item())\n",
        "print(output[0][0])\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 100])\n",
            "tensor([ 2.1983, -2.4517, -2.0884,  0.4074, -2.0277,  0.4489,  2.8894, -3.8463,\n",
            "         3.2029,  2.0145, -2.3532, -3.0322, -1.7299, -1.6727,  2.0970,  2.5279,\n",
            "         2.3845,  2.5020, -1.9817, -1.3141,  2.1490, -0.7359, -2.3999, -2.7993,\n",
            "         3.4808, -0.2314,  2.7411, -2.1603,  1.3329,  2.5883,  1.3455,  2.1759,\n",
            "        -1.0607,  2.4408,  2.6574,  2.0142, -1.8354, -1.4377, -1.9669, -1.4518,\n",
            "         2.3125, -2.1434,  2.9136,  2.4547,  1.3745, -2.0245,  2.9080,  2.1267,\n",
            "        -2.7334,  2.1076, -2.4617,  0.9319, -2.0164, -1.9049, -0.0190,  0.6383,\n",
            "         2.6601, -2.4824,  0.3906, -1.8532, -2.6333,  1.2519, -0.8801,  0.8934,\n",
            "        -2.4112,  2.7612, -0.6366, -1.5770,  2.1413, -2.4599, -2.1904, -1.2095,\n",
            "        -2.4878, -0.7620,  2.5534,  2.7037,  2.4145, -2.3148, -0.8629, -1.7082,\n",
            "        -2.2258,  3.2913,  1.2394, -1.2462, -1.2017, -2.5013,  2.3004,  2.2218,\n",
            "        -0.7199, -0.9381,  2.9387, -2.3558, -1.7926,  1.8543, -1.8983, -0.7422,\n",
            "         1.6102,  2.5319,  1.3203, -1.7782], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "0.32185471057891846\n",
            "0.16088587045669556\n",
            "tensor([[ 1.0427e-02,  7.2285e-03,  6.1953e-03,  8.0018e-03,  6.4188e-03,\n",
            "          7.4352e-03,  5.8122e-03,  7.1637e-03,  5.7844e-03,  7.4770e-03,\n",
            "          8.1656e-03,  9.2895e-03,  9.2842e-03, -2.2239e-05,  3.7483e-03,\n",
            "          3.3233e-03],\n",
            "        [ 1.0259e-02,  1.8777e-03, -2.5915e-03,  1.6156e-02,  1.4068e-02,\n",
            "          1.3555e-02,  9.6613e-03,  9.9267e-03,  9.0569e-03,  1.0031e-02,\n",
            "          1.1792e-02,  1.1222e-02,  1.1561e-02,  2.7820e-03,  1.4924e-02,\n",
            "          1.8803e-02],\n",
            "        [ 1.0993e-02, -2.7631e-04,  8.7517e-03,  2.2010e-02,  1.6482e-02,\n",
            "          1.8178e-02,  1.0347e-02,  1.4997e-02,  9.8603e-03,  1.5250e-02,\n",
            "          1.3390e-02,  1.6767e-02,  1.6581e-02,  9.1247e-03,  2.4749e-02,\n",
            "          1.1677e-02],\n",
            "        [ 1.6716e-02,  4.4794e-03,  8.0862e-03,  1.5119e-02,  1.3639e-02,\n",
            "          1.2051e-02,  6.0596e-03,  9.5691e-03,  5.8495e-03,  1.0194e-02,\n",
            "          9.5833e-03,  1.3691e-02,  1.2113e-02,  7.4531e-04,  1.2009e-02,\n",
            "          8.6337e-03],\n",
            "        [ 1.1914e-02,  5.7349e-03,  2.3869e-03,  1.2552e-02,  9.2677e-03,\n",
            "          8.2700e-03,  3.8263e-03,  6.0281e-03,  3.5882e-03,  6.5143e-03,\n",
            "          7.4567e-03,  9.7612e-03,  9.5836e-03, -9.6356e-04,  1.2352e-02,\n",
            "          8.2253e-03],\n",
            "        [ 1.3995e-02,  4.0632e-03,  4.0903e-03,  1.0352e-02,  7.1281e-03,\n",
            "          6.0381e-03,  7.1320e-04,  4.6620e-03,  7.5684e-04,  5.0866e-03,\n",
            "          4.0057e-03,  1.0025e-02,  7.7814e-03, -1.7326e-03,  7.2812e-03,\n",
            "          5.8930e-03],\n",
            "        [ 9.0088e-03,  3.5719e-03, -3.2041e-04,  9.5824e-03,  8.9996e-03,\n",
            "          6.2905e-03,  3.8196e-03,  4.0166e-03,  3.6630e-03,  4.3858e-03,\n",
            "          7.2210e-03,  9.3792e-03,  8.6070e-03, -1.8364e-04,  1.0566e-02,\n",
            "          1.0096e-02],\n",
            "        [ 1.2683e-02,  2.5642e-03,  3.5839e-03,  9.8810e-03,  7.4085e-03,\n",
            "          6.1076e-03,  9.1186e-04,  4.8474e-03,  8.3163e-04,  5.0348e-03,\n",
            "          3.5765e-03,  9.5642e-03,  7.8325e-03, -6.5787e-04,  8.3980e-03,\n",
            "          6.3736e-03],\n",
            "        [ 8.7688e-03,  3.4157e-03, -4.2702e-04,  9.4549e-03,  9.1048e-03,\n",
            "          6.3791e-03,  3.8050e-03,  4.0134e-03,  3.6320e-03,  4.2590e-03,\n",
            "          7.1144e-03,  9.3644e-03,  8.6344e-03, -6.9142e-05,  1.0663e-02,\n",
            "          1.0168e-02],\n",
            "        [ 1.2979e-02,  2.7076e-03,  3.6999e-03,  1.0349e-02,  7.5779e-03,\n",
            "          6.2815e-03,  1.0305e-03,  4.8941e-03,  9.2290e-04,  5.2459e-03,\n",
            "          3.5965e-03,  9.8924e-03,  8.0088e-03, -7.4371e-04,  8.7865e-03,\n",
            "          6.5649e-03],\n",
            "        [ 1.1228e-02,  4.7100e-03,  1.0202e-03,  1.1846e-02,  1.0385e-02,\n",
            "          8.9125e-03,  5.0237e-03,  6.0545e-03,  4.5431e-03,  6.4542e-03,\n",
            "          8.9538e-03,  1.1814e-02,  1.0962e-02,  2.5218e-04,  1.1754e-02,\n",
            "          1.1084e-02],\n",
            "        [ 1.6599e-02,  3.5633e-03,  5.4611e-03,  1.4453e-02,  1.3090e-02,\n",
            "          1.1646e-02,  5.6554e-03,  8.4757e-03,  5.3033e-03,  9.1071e-03,\n",
            "          8.0531e-03,  1.3621e-02,  1.2366e-02,  1.8140e-03,  1.3283e-02,\n",
            "          1.0572e-02],\n",
            "        [ 1.4799e-02,  4.8217e-03,  3.9485e-03,  1.7921e-02,  1.5075e-02,\n",
            "          1.6286e-02,  1.0544e-02,  1.3540e-02,  1.0199e-02,  1.4080e-02,\n",
            "          1.5612e-02,  1.8088e-02,  1.9080e-02,  5.1420e-03,  1.7601e-02,\n",
            "          1.4168e-02],\n",
            "        [ 8.8296e-03, -1.7455e-03,  2.6760e-03,  1.3854e-02,  1.1229e-02,\n",
            "          1.1685e-02,  6.7545e-03,  9.3154e-03,  6.3631e-03,  9.3852e-03,\n",
            "          7.7875e-03,  1.1038e-02,  1.1145e-02,  4.0454e-03,  1.6762e-02,\n",
            "          1.0127e-02],\n",
            "        [ 8.6034e-03,  3.7813e-03,  1.2880e-02,  6.7299e-03,  5.2384e-03,\n",
            "          6.3964e-03,  4.4548e-03,  8.4178e-03,  4.7439e-03,  8.7816e-03,\n",
            "          7.3092e-03,  1.1403e-02,  9.4428e-03,  2.1219e-03,  3.6460e-03,\n",
            "         -4.1233e-03],\n",
            "        [ 6.5809e-03,  6.3907e-03, -1.3365e-03, -1.4762e-03, -9.9557e-04,\n",
            "         -4.7410e-04,  5.9823e-04, -4.2814e-05,  7.6300e-04,  1.5089e-04,\n",
            "          2.1599e-03,  1.5589e-03,  2.2045e-03, -5.3922e-03, -5.1220e-03,\n",
            "          1.6104e-03]], device='cuda:0', grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5OqCyq_ayAP",
        "colab_type": "code",
        "outputId": "22fcba23-c153-4457-a2ca-ac8548654b19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "4000/16"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlUmhBU1ayAS",
        "colab_type": "code",
        "outputId": "15f8654a-fe8a-4884-9cca-c6577b168228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(validation.size())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([400, 512, 16, 16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8tHWKdBayAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f95cad21-b08b-4002-f298-2aab169fe2f8"
      },
      "source": [
        "np.tanh(0.9)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7162978701990245"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0CC5aErgHUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}