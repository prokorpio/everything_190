{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wwzwgvVmax_-"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from models_to_prune import *\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torchvision.transforms as tf\n",
    "import torchvision.datasets as ds\n",
    "import torch.utils.data as data\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "W0zqCF0payAE",
    "outputId": "16186faa-a151-49ce-e57e-0eb9a9b62ceb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 : torch.Size([64, 3, 3, 3])\n",
      "pooled : torch.Size([64, 3])\n",
      "conv2 : torch.Size([128, 64, 3, 3])\n",
      "pooled : torch.Size([128, 64])\n",
      "conv3 : torch.Size([256, 128, 3, 3])\n",
      "pooled : torch.Size([256, 128])\n",
      "conv4 : torch.Size([512, 256, 3, 3])\n",
      "pooled : torch.Size([512, 256])\n",
      "tensor(0.0071)\n"
     ]
    }
   ],
   "source": [
    "# See layer shapes\n",
    "cnn = BasicCNN()\n",
    "for name, layer in cnn.named_modules():\n",
    "    if 'conv' in name:\n",
    "        filters = layer.weight.data.clone()\n",
    "        print(name,':',filters.size())\n",
    "        # reduce last dim of 3x3 to 1x1 then squeeze\n",
    "        pooled_filter = torch.squeeze(F.avg_pool2d(filters,\n",
    "                                                   filters.size()[-1])) \n",
    "        pooled_filter = pooled_filter*1000 # scaling up the magnitudes \n",
    "        print(\"pooled :\",pooled_filter.size())\n",
    "\n",
    "# interpet 4d tensors as set of 3d blocks.  \n",
    "#print(pooled_filter[0])\n",
    "print(pooled_filter.cpu().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BPTbq-pDayAI"
   },
   "outputs": [],
   "source": [
    "# Create \"dataset\" of pooled layers\n",
    "# Convert set of 3d blocks to set of flat 2d maps. \n",
    "\n",
    "# Create pad-tensor container, same size as biggest layer\n",
    "filter_repeats = 10000 # each filter layer will be repeated this many times\n",
    "feat_size = 16  # size of 2d maps\n",
    "magnitude_scaler = 100\n",
    "state_rep = torch.zeros([filter_repeats, 512, feat_size,feat_size]) # set of N padded [512,16,16] \n",
    "                                                        # tensors for each of the 4 layers  \n",
    "for i in range(filter_repeats):\n",
    "    cnn = BasicCNN()\n",
    "    for name, layer in cnn.named_modules():\n",
    "        if 'conv' in name:\n",
    "            filters = layer.weight.data.clone()\n",
    "            pooled_filter = torch.squeeze(F.avg_pool2d(filters,\n",
    "                                                       filters.size()[-1]))\n",
    "            pooled_filter = pooled_filter*magnitude_scaler # scaling up the magnitudes \n",
    "            conv_layer_num = int(name[-1])\n",
    "            size = pooled_filter.size()\n",
    "            #if conv_layer_num == 1:\n",
    "            #    pads = (feat_size//2) - size[-1]//2\n",
    "            #    state_rep[i, :size[0], feat_size//2, pads-1 :-pads] = pooled_filter  # copy in center\n",
    "            #elif conv_layer_num == 2:\n",
    "            #    pads = (feat_size//2) - 4\n",
    "            #    state_rep[i+filter_repeats, :size[0], pads:-pads, pads:-pads] = pooled_filter.view(size[0],8,8)\n",
    "            #elif conv_layer_num == 3:\n",
    "            #    pads_r = (feat_size//2) - 4\n",
    "            #    pads_c = (feat_size//2) - 8\n",
    "            #    state_rep[i+filter_repeats*2, :size[0], :8, :16] = pooled_filter.view(size[0],8,16)\n",
    "            if conv_layer_num == 4:\n",
    "                state_rep[i] = pooled_filter.view(size[0],16,16) # same size as init state_rep\n",
    "                #state_rep[i+filter_repeats*3] = pooled_filter.view(size[0],16,16) # same size as init state_rep\n",
    "                #print(state_rep[i+filter_repeats*3][0])\n",
    "\n",
    "val_rep = filter_repeats//10\n",
    "validation = torch.zeros([val_rep*4, 512, feat_size,feat_size]) # set of N padded [512,16,16] \n",
    "                                                        # tensors for each of the 4 layers  \n",
    "for i in range(val_rep):\n",
    "    cnn = BasicCNN()\n",
    "    for name, layer in cnn.named_modules():\n",
    "        if 'conv' in name:\n",
    "            filters = layer.weight.data.clone()\n",
    "            pooled_filter = torch.squeeze(F.avg_pool2d(filters,\n",
    "                                                       filters.size()[-1]))\n",
    "            pooled_filter = pooled_filter*magnitude_scaler # scaling up the magnitudes \n",
    "            conv_layer_num = int(name[-1])\n",
    "            size = pooled_filter.size()\n",
    "            if conv_layer_num == 1:\n",
    "                pads = (feat_size//2) - size[-1]//2\n",
    "                validation[i, :size[0], feat_size//2, pads-1 :-pads] = pooled_filter  # copy in center\n",
    "            elif conv_layer_num == 2:\n",
    "                pads = (feat_size//2) - 4\n",
    "                validation[i+val_rep, :size[0], pads:-pads, pads:-pads] = pooled_filter.view(size[0],8,8)\n",
    "            elif conv_layer_num == 3:\n",
    "                pads_r = (feat_size//2) - 4\n",
    "                pads_c = (feat_size//2) - 8\n",
    "                validation[i+val_rep*2, :size[0], :8, :16] = pooled_filter.view(size[0],8,16)\n",
    "            elif conv_layer_num == 4:\n",
    "                validation[i+val_rep*3] = pooled_filter.view(size[0],16,16) # same size as init state_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "1z_Nn433ayAK",
    "outputId": "ee5199dc-0096-456d-e1c6-8896fb1e2884"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d22cf8fcec22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DL_Codes/torch_venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \"\"\"\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DL_Codes/torch_venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DL_Codes/torch_venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DL_Codes/torch_venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DL_Codes/torch_venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \"\"\"\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DL_Codes/torch_venv/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m             raise RuntimeError(\n\u001b[1;32m    191\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DL_Codes/torch_venv/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# Build Autoencoder Class, modified from https://github.com/L1aoXingyu\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoding_dim = 64\n",
    "        self.encoder = nn.Sequential( # input size is [512,16,16]\n",
    "            nn.Conv2d(512, 256, 3),  # b, 256, 14, 14\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(4, stride=1),  # b, 256, 11, 11\n",
    "            nn.Conv2d(256, 128, 3),  # b, 128, 9, 9\n",
    "            \n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(3, stride=1),  # b, 128, 7, 7\n",
    "            nn.Conv2d(128, 64, 3),  # b, 64, 5, 5\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, stride=1),# b, 64, 4, 4\n",
    "\n",
    "            nn.Flatten(), #from dim=1 to -1\n",
    "            nn.Linear(64*4*4,self.encoding_dim)\n",
    "        )\n",
    "        \n",
    "        self.latent_to_map = nn.Linear(self.encoding_dim, 64*4*4)\n",
    "        self.decoder = nn.Sequential(    \n",
    "            nn.ConvTranspose2d(64, 128, 4, stride=1),  # b, 64,7,7\n",
    "            nn.Sigmoid(),\n",
    "            nn.ConvTranspose2d(128, 256, 5, stride=1),  # b, 256, 11, 11\n",
    "            nn.Sigmoid(),\n",
    "            nn.ConvTranspose2d(256, 512, 6),  # b, 512, 16, 16\n",
    "          #  nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.latent_to_map(x).view(-1,64,4,4) \n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "model = autoencoder().cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 939
    },
    "colab_type": "code",
    "id": "9dmjgKJCbUMC",
    "outputId": "ffb54d14-0af3-4740-9d08-c6b464bb3195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/10], loss:0.3417483866214752, val_loss:1.3761440515518188, rand_loss:0.5805090665817261\n",
      "epoch [1/10], loss:0.33293068408966064, val_loss:0.16735203564167023, rand_loss:0.5801882743835449\n",
      "epoch [1/10], loss:0.3233155310153961, val_loss:0.13830313086509705, rand_loss:0.5806146264076233\n",
      "epoch [1/10], loss:0.3228972852230072, val_loss:0.13621152937412262, rand_loss:0.5800780653953552\n",
      "epoch [1/10], loss:0.3225247263908386, val_loss:0.13382185995578766, rand_loss:0.5803004503250122\n",
      "epoch [1/10], loss:0.3219667673110962, val_loss:0.13134582340717316, rand_loss:0.580004870891571\n",
      "epoch [1/10], loss:0.32168716192245483, val_loss:0.1291329562664032, rand_loss:0.5801371932029724\n",
      "epoch [1/10], loss:0.32225286960601807, val_loss:0.12731145322322845, rand_loss:0.5809592008590698\n",
      "epoch [1/10], loss:0.32205507159233093, val_loss:0.1259191930294037, rand_loss:0.5805268883705139\n",
      "epoch [1/10], loss:0.32172659039497375, val_loss:0.12491466850042343, rand_loss:0.5807982087135315\n",
      "epoch [1/10], loss:0.32194849848747253, val_loss:0.1242263913154602, rand_loss:0.5805700421333313\n",
      "epoch [1/10], loss:0.3221557140350342, val_loss:0.12376321107149124, rand_loss:0.5804152488708496\n",
      "epoch [1/10], loss:0.321880578994751, val_loss:0.12345761060714722, rand_loss:0.5803701877593994\n",
      "epoch [1/10], loss:0.32179781794548035, val_loss:0.12325238436460495, rand_loss:0.5800889730453491\n",
      "epoch [1/10], loss:0.3217727541923523, val_loss:0.12311168760061264, rand_loss:0.5803280472755432\n",
      "epoch [1/10], loss:0.32169175148010254, val_loss:0.12301301211118698, rand_loss:0.5803384780883789\n",
      "epoch [1/10], loss:0.3216724395751953, val_loss:0.12293880432844162, rand_loss:0.5800679922103882\n",
      "epoch [1/10], loss:0.3216784596443176, val_loss:0.12287145853042603, rand_loss:0.580451250076294\n",
      "epoch [1/10], loss:0.32163870334625244, val_loss:0.12281637638807297, rand_loss:0.580285906791687\n",
      "epoch [1/10], loss:0.32156577706336975, val_loss:0.1227715015411377, rand_loss:0.5801142454147339\n",
      "epoch [1/10], loss:0.3216061592102051, val_loss:0.12272511422634125, rand_loss:0.5803765058517456\n",
      "epoch [1/10], loss:0.32173630595207214, val_loss:0.12268009036779404, rand_loss:0.580035924911499\n",
      "epoch [1/10], loss:0.3219035863876343, val_loss:0.12263844162225723, rand_loss:0.5804972648620605\n",
      "epoch [1/10], loss:0.32161155343055725, val_loss:0.12261851131916046, rand_loss:0.580112099647522\n",
      "epoch [1/10], loss:0.321464866399765, val_loss:0.12259373068809509, rand_loss:0.5801562070846558\n",
      "epoch [1/10], loss:0.32145994901657104, val_loss:0.12255093455314636, rand_loss:0.5803244113922119\n",
      "epoch [1/10], loss:0.3216885030269623, val_loss:0.12252577394247055, rand_loss:0.5803537964820862\n",
      "epoch [1/10], loss:0.32183510065078735, val_loss:0.12250925600528717, rand_loss:0.5800981521606445\n",
      "epoch [1/10], loss:0.3216492533683777, val_loss:0.12248299270868301, rand_loss:0.5805873274803162\n",
      "epoch [1/10], loss:0.3219309449195862, val_loss:0.12246257811784744, rand_loss:0.5801219940185547\n",
      "epoch [1/10], loss:0.32149165868759155, val_loss:0.12244944274425507, rand_loss:0.5802165865898132\n",
      "epoch [1/10], loss:0.3218345642089844, val_loss:0.12243341654539108, rand_loss:0.5802851319313049\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-2fd2f92a7064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mave_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mval_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 16\n",
    "learning_rate = 1e-3\n",
    "\n",
    "state_rep = state_rep.to(device)\n",
    "train_dl = DataLoader(state_rep, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(validation, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = autoencoder().cuda()\n",
    "MSE_criterion = nn.MSELoss()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "                                                # removed weight_decay=1e-5\n",
    "#sample = iter(train_dl).next()\n",
    "#print(sample.cpu().mean())\n",
    "#raise KeyboardInterrupt\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(train_dl):\n",
    "        model.train()\n",
    "        data = Variable(data).cuda()\n",
    "        # ===================forward=====================\n",
    "        output = model(data)\n",
    "        #loss = torch.sum(torch.log(torch.cosh(data-output)))\n",
    "        loss = torch.mean(torch.abs(data-output)) # MAE criterion\n",
    "        rand_loss = torch.mean(torch.abs(data-torch.rand_like(output))) # sanity check\n",
    "        #loss = MSE_criterion(output, data)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "         # ===================log========================\n",
    "        if i % 100 == 0:\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            num_batches = 0\n",
    "            ave_val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for val in valid_dl:\n",
    "                    val = Variable(val).cuda()\n",
    "                    val_output = model(val)\n",
    "                    #val_loss += torch.sum(torch.log(torch.cosh(val-val_output)))\n",
    "                    val_loss += torch.mean(torch.abs(val - val_output))\n",
    "                    #val_loss += MSE_criterion(val_output,val)\n",
    "                    num_batches += 1\n",
    "                ave_val_loss = val_loss/num_batches\n",
    "\n",
    "\n",
    "            print('epoch [{}/{}], loss:{}, val_loss:{}, rand_loss:{}'\n",
    "                .format(epoch+1, num_epochs, loss.item(), ave_val_loss, rand_loss.item()))\n",
    "            torch.save(model.state_dict(), './conv_autoencoder.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8AyOdWhXayAM",
    "outputId": "c2599daa-7f26-4245-d524-6dce5e62736c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state tensor([-17.4888,  18.0066,  17.0586,  14.4316,  14.7896, -16.4168,  16.9968,\n",
      "        -14.5779,  16.9388,  13.2094, -17.6883,  16.8518,  17.0385,  16.2804,\n",
      "        -18.0836, -16.9522, -16.6398,  12.9838, -15.2124, -13.8010, -14.3395,\n",
      "        -16.2428, -16.9159,  12.2531, -16.2711, -15.0062, -17.0960,  13.8540,\n",
      "        -13.6134, -16.9885, -17.8857,  15.7302, -14.2018,  15.6985,  14.5939,\n",
      "        -13.6271, -15.4689,  17.4191, -14.3462, -16.1832,  15.7112,  15.9662,\n",
      "        -15.3835,  16.2491, -13.0086,  15.0600,  16.1198, -17.1797,  17.3870,\n",
      "         12.6326, -16.2113, -17.7815,  16.0003, -16.2986,  15.8285,  15.7786,\n",
      "        -16.7244, -16.7356, -16.4347, -17.6033,  14.9225, -10.8156, -17.7371,\n",
      "        -16.2979], grad_fn=<SelectBackward>)\n",
      "state tensor([-17.4888,  18.0066,  17.0586,  14.4316,  14.7896, -16.4168,  16.9968,\n",
      "        -14.5779,  16.9388,  13.2094, -17.6883,  16.8518,  17.0385,  16.2804,\n",
      "        -18.0836, -16.9522, -16.6398,  12.9838, -15.2124, -13.8010, -14.3395,\n",
      "        -16.2428, -16.9159,  12.2531, -16.2711, -15.0062, -17.0960,  13.8540,\n",
      "        -13.6134, -16.9885, -17.8857,  15.7302, -14.2018,  15.6985,  14.5939,\n",
      "        -13.6271, -15.4689,  17.4191, -14.3462, -16.1832,  15.7112,  15.9662,\n",
      "        -15.3835,  16.2491, -13.0086,  15.0600,  16.1198, -17.1797,  17.3870,\n",
      "         12.6326, -16.2113, -17.7815,  16.0003, -16.2986,  15.8285,  15.7786,\n",
      "        -16.7244, -16.7356, -16.4347, -17.6033,  14.9225, -10.8156, -17.7371,\n",
      "        -16.2979], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(encoded_states.size())\\n#print(encoded_states[1])\\noutput_ = loaded_model(data)\\nMAE_loss = torch.mean(torch.abs(data-output))\\nMSE_loss = MSE_criterion(output, data)\\nprint(MAE_loss.item())\\nprint(MSE_loss.item())\\nprint(output[0][0])\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEBUG: Output of encoder_ is always the same. Something's wrong with loading autoencoder.encoder\n",
    "\n",
    "import copy\n",
    "\n",
    "batch_size = 16\n",
    "state_rep = state_rep.to(device)\n",
    "train_dl = DataLoader(state_rep, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(validation, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "loaded_model = autoencoder().to(device)\n",
    "checkpoint_dict = torch.load('conv_autoencoder.pth', map_location=device)\n",
    "loaded_model.load_state_dict(checkpoint_dict)\n",
    "#print(loaded_model.encoder.state_dict())\n",
    "encoder_ = loaded_model.encoder\n",
    "#encoded_states = loaded_model.encoder(data)\n",
    "for i, data in enumerate(train_dl): \n",
    "    states = encoder_(data)\n",
    "    print(\"state\",states[0])\n",
    "    if i+1 == 2:\n",
    "        break\n",
    "\n",
    "'''\n",
    "print(encoded_states.size())\n",
    "#print(encoded_states[1])\n",
    "output_ = loaded_model(data)\n",
    "MAE_loss = torch.mean(torch.abs(data-output))\n",
    "MSE_loss = MSE_criterion(output, data)\n",
    "print(MAE_loss.item())\n",
    "print(MSE_loss.item())\n",
    "print(output[0][0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "X5OqCyq_ayAP",
    "outputId": "22fcba23-c153-4457-a2ca-ac8548654b19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250.0"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4000/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wlUmhBU1ayAS",
    "outputId": "15f8654a-fe8a-4884-9cca-c6577b168228"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 512, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "print(validation.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o8tHWKdBayAU",
    "outputId": "f95cad21-b08b-4002-f298-2aab169fe2f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7162978701990245"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tanh(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\n",
      "conv2\n"
     ]
    }
   ],
   "source": [
    "model = BasicCNN()    \n",
    "children = model.named_children()\n",
    "for name1, module in children:\n",
    "    if 'conv' in name:\n",
    "        conv_layer = module\n",
    "        name2, next_conv_layer = next(children)\n",
    "        print(name1)\n",
    "        print(name2)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\n",
      "conv1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "state_rep_autoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch_venv",
   "language": "python",
   "name": "torch_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
